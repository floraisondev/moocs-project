install.packages("fpc")
library(cluster)
pam(k.data1, 3, metric = "manhattan")
dfPam<-pam(k.data1,3,metric = "manhattan")
dfPam
dfPam$medoids
install.packages('factoextra')
library(factoextra)
fviz_cluster(dfPam,stand=F, geom = "point",ellipse.type = "norm", ellipse.level = 0.7,palette = "jco",ggtheme = theme_minimal())
fviz_nbclust(dfPam, pam, method = "silhouette") + theme_classic()
install.packages("factoextra")
fviz_cluster(dfPam,stand=F, geom = "point",ellipse.type = "norm", ellipse.level = 0.7,palette = "jco",ggtheme = theme_minimal())
fviz_nbclust(dfPam, pam, method = "silhouette") + theme_classic()
k.data1 <- read.csv( "reg.csv", header = TRUE )
head( k.data1 )
install.packages("fpc")
library(cluster)
pam(k.data1, 3, metric = "manhattan")
dfPam<-pam(k.data1,3,metric = "manhattan")
dfPam
dfPam$medoids
install.packages('factoextra')
library(factoextra)
fviz_cluster(dfPam,stand=F, geom = "point",ellipse.type = "norm", ellipse.level = 0.7,palette = "jco",ggtheme = theme_minimal())
k.data <- read.csv( ("Workbook8.csv"), header = TRUE )
head( k.data )
dataframe<-k.data[1:434,]
dataframe$Group=NULL
str(dataframe)
hist(dataframe$Cluster)
dim(dataframe)
apply(dataframe,2,range)
maxvalue<-apply(dataframe,2,max)
maxvalue
minvalue<-apply(dataframe,2,min)
minvalue
dataframe<-as.data.frame(scale(dataframe,center=minvalue,scale=maxvalue-minvalue))
library(caret)
set.seed(3033)
intrain <- createDataPartition(y = dataframe$Cluster, p= 0.8, list = FALSE)
training <- dataframe[intrain,]
testing <- dataframe[-intrain,]
training[["Cluster"]] = factor(training[["Cluster"]])
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
set.seed(3233)
svm_Linear <- train(Cluster ~., data = training, method = "svmLinear",
trControl=trctrl,
preProcess = c("center", "scale"),
tuneLength = 10)
#plot(svm_Linear)
test_pred <- predict(svm_Linear, newdata = testing,method="class")
tail( test_pred,1)
confusionMatrix(test_pred, testing$Cluster )
#tail(test_pred,1)
library(R.utils)
k.data2 <- read.csv( "new_data.csv", header = TRUE )
#v<-c(1,25-35,25,10,4,3,8,1)
Age<-35
#Age<-as.data.frame(scale(Age,center=15,scale=65-15))
Expected.Course.Duration<-8
#Expected.Course.Duration<-as.data.frame(scale(Expected.Course.Duration,center=5,scale=17-5))
Interest<-5
#Interest<-as.data.frame(scale(Interest,center=5,scale=5-1))
Qualification<-4
#Qualification<-as.data.frame(scale(Qualification,center=0,scale=5-0))
Course.ID<-3
#Course.ID<-as.data.frame(scale(Course.ID,center=1,scale=57-1))
Gender<-0
#Gender<-as.data.frame(scale(Gender,center=0,scale=2-0))
v<-c(Age,Expected.Course.Duration,Interest,Qualification,Course.ID,Gender)
v1<-k.data2[435,]
#test_pred <- predict(svm_Linear, newdata =k.data2[435,] ,method="class")
test_pred <- predict(svm_Linear, newdata =v ,method="class")
print(test_pred)
x<-test_pred
if(x==0)
C<-"cluster1"
if(x==0.5)
C<-"cluster2"
if(x==1)
C<-"cluter3"
print(C)
k.data <- read.csv( ("Workbook8.csv"), header = TRUE )
head( k.data )
dataframe<-k.data[1:434,]
dataframe$Group=NULL
str(dataframe)
hist(dataframe$Cluster)
dim(dataframe)
apply(dataframe,2,range)
maxvalue<-apply(dataframe,2,max)
maxvalue
minvalue<-apply(dataframe,2,min)
minvalue
dataframe<-as.data.frame(scale(dataframe,center=minvalue,scale=maxvalue-minvalue))
library(caret)
set.seed(3033)
intrain <- createDataPartition(y = dataframe$Cluster, p= 0.8, list = FALSE)
training <- dataframe[intrain,]
testing <- dataframe[-intrain,]
training[["Cluster"]] = factor(training[["Cluster"]])
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
set.seed(3233)
svm_Linear <- train(Cluster ~., data = training, method = "svmLinear",
trControl=trctrl,
preProcess = c("center", "scale"),
tuneLength = 10)
#plot(svm_Linear)
test_pred <- predict(svm_Linear, newdata = testing,method="class")
tail( test_pred,1)
confusionMatrix(test_pred, testing$Cluster )
#tail(test_pred,1)
library(R.utils)
k.data2 <- read.csv( "new_data.csv", header = TRUE )
#v<-c(1,25-35,25,10,4,3,8,1)
Age<-35
#Age<-as.data.frame(scale(Age,center=15,scale=65-15))
Expected.Course.Duration<-8
#Expected.Course.Duration<-as.data.frame(scale(Expected.Course.Duration,center=5,scale=17-5))
Interest<-5
#Interest<-as.data.frame(scale(Interest,center=5,scale=5-1))
Qualification<-4
#Qualification<-as.data.frame(scale(Qualification,center=0,scale=5-0))
Course.ID<-3
#Course.ID<-as.data.frame(scale(Course.ID,center=1,scale=57-1))
Gender<-0
#Gender<-as.data.frame(scale(Gender,center=0,scale=2-0))
v<-c(Age,Expected.Course.Duration,Interest,Qualification,Course.ID,Gender)
v1<-k.data2[435,]
#test_pred <- predict(svm_Linear, newdata =k.data2[435,] ,method="class")
test_pred <- predict(svm_Linear, newdata =v ,method="class")
print(test_pred)
x<-test_pred
if(x==0)
C<-"cluster1"
if(x==0.5)
C<-"cluster2"
if(x==1)
C<-"cluter3"
print(C)
k.data1 <- read.csv( "reg.csv", header = TRUE )
head( k.data1 )
install.packages("fpc")
library(cluster)
pam(k.data1, 3, metric = "manhattan")
dfPam<-pam(k.data1,3,metric = "manhattan")
dfPam
dfPam$medoids
install.packages('factoextra')
install.packages("factoextra")
library(factoextra)
fviz_cluster(dfPam,stand=F, geom = "point",ellipse.type = "norm", ellipse.level = 0.7,palette = "jco",ggtheme = theme_minimal())
fviz_nbclust(dfPam, pam, method = "silhouette") + theme_classic()
k.data1 <- read.csv( "reg.csv", header = TRUE )
head( k.data1 )
install.packages("fpc")
library(cluster)
scaleddata = scale(k.data1)
k.data1 <- read.csv( "reg.csv", header = TRUE )
head( k.data1 )
install.packages("fpc")
library(cluster)
scaleddata = scale(k.data1)
fviz_nbclust(3, pam, method ="silhouette")+theme_minimal()
library(cluster)
pam(k.data1, 3, metric = "manhattan")
k.data1 <- read.csv( "reg.csv", header = TRUE )
head( k.data1 )
install.packages("fpc")
library(cluster)
viz_nbclust(k.data1, pam, method ="silhouette")+theme_minimal()
k.data1 <- read.csv( "reg.csv", header = TRUE )
head( k.data1 )
install.packages("fpc")
library(cluster)
fviz_nbclust(k.data1, pam, method ="silhouette")+theme_minimal()
k.data1 <- read.csv( "reg.csv", header = TRUE )
install.packages("fpc")
library(cluster)
fviz_nbclust(k.data1, pam, method ="silhouette")+theme_minimal()
k.data1 <- read.csv( "reg.csv", header = TRUE )
head(k.data1)
install.packages("fpc")
library(cluster)
dist(k.data1)
fviz_nbclust(k.data1, pam, method ="silhouette")+theme_minimal()
pam(k.data1, 3, metric = "manhattan")
dfPam<-pam(k.data1,3,metric = "manhattan")
dfPam
dfPam$medoids
install.packages('factoextra')
install.packages("factoextra")
shiny::runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
k.data <- read.csv( ("Workbook8.csv"), header = TRUE )
head( k.data )
dataframe<-k.data[1:434,]
dataframe$Group=NULL
str(dataframe)
hist(dataframe$Cluster)
dim(dataframe)
apply(dataframe,2,range)
maxvalue<-apply(dataframe,2,max)
maxvalue
minvalue<-apply(dataframe,2,min)
minvalue
dataframe<-as.data.frame(scale(dataframe,center=minvalue,scale=maxvalue-minvalue))
library(caret)
set.seed(3033)
intrain <- createDataPartition(y = dataframe$Cluster, p= 0.8, list = FALSE)
training <- dataframe[intrain,]
testing <- dataframe[-intrain,]
training[["Cluster"]] = factor(training[["Cluster"]])
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
set.seed(3233)
svm_Linear <- train(Cluster ~., data = training, method = "svmLinear",
trControl=trctrl,
preProcess = c("center", "scale"),
tuneLength = 10)
#plot(svm_Linear)
test_pred <- predict(svm_Linear, newdata = testing,method="class")
tail( test_pred,1)
svm_Linear <- train(Cluster ~., data = training, method = "svmLinear",
trControl=trctrl,
preProcess = c("center", "scale"),
tuneLength = 10)
plot(svm_Linear)
test_pred <- predict(svm_Linear, newdata = testing,method="class")
tail( test_pred,1)
confusionMatrix(test_pred, testing$Cluster )
#tail(test_pred,1)
library(R.utils)
k.data2 <- read.csv( "new_data.csv", header = TRUE )
#v<-c(1,25-35,25,10,4,3,8,1)
Age<-35
#Age<-as.data.frame(scale(Age,center=15,scale=65-15))
Expected.Course.Duration<-8
#Expected.Course.Duration<-as.data.frame(scale(Expected.Course.Duration,center=5,scale=17-5))
Interest<-5
#Interest<-as.data.frame(scale(Interest,center=5,scale=5-1))
Qualification<-4
#Qualification<-as.data.frame(scale(Qualification,center=0,scale=5-0))
Course.ID<-3
#Course.ID<-as.data.frame(scale(Course.ID,center=1,scale=57-1))
Gender<-0
#Gender<-as.data.frame(scale(Gender,center=0,scale=2-0))
v<-c(Age,Expected.Course.Duration,Interest,Qualification,Course.ID,Gender)
v1<-k.data2[435,]
#test_pred <- predict(svm_Linear, newdata =k.data2[435,] ,method="class")
test_pred <- predict(svm_Linear, newdata =v ,method="class")
print(test_pred)
x<-test_pred
if(x==0)
C<-"cluster1"
if(x==0.5)
C<-"cluster2"
if(x==1)
C<-"cluter3"
print(C)
shiny::runApp()
shiny::runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
library(MASS)
library(rpart)
set.seed(123)
k.data1 <- read.csv( "Workbook8.csv", header = TRUE )
head( k.data1 )
dataframe<-k.data1
dataframe$Group=NULL
dataframe$Gender=NULL
#dataframe$x1=NULL
head(dataframe)
#dataframe<- Boston
str(dataframe)
hist(dataframe$Cluster)
dim(dataframe)
apply(dataframe,2,range)
maxvalue<-apply(dataframe,2,max)
maxvalue
minvalue<-apply(dataframe,2,min)
minvalue
dataframe<-as.data.frame(scale(dataframe,center=minvalue,scale=maxvalue-minvalue))
#ind<-sample(1:nrow(dataframe),350)
#traindf<-dataframe[1:350,]
#testdf<-dataframe[351:434,]
str(dataframe)
set.seed(450)
outs<-NULL
k<-20
library(plyr)
pbar<-create_progress_bar('text')
pbar$init(k)
for(i in 1:k){
index<-sample(1:nrow(dataframe),round(0.8*nrow(dataframe)))
train.cv<-dataframe[index,]
test.cv<-dataframe[-index,]
dtmodel<-rpart(Cluster ~ . ,data=train.cv,method='class')
#printcp(dtmodel)
#plotcp(dtmodel)
#plot(dtmodel,uniform=TRUE)
#text(dtmodel, use.n=TRUE, all=TRUE, cex=.8)
#post(dtmodel, file = "dt.ps")
#text(dtmodel)
#summary(dtmodel)
predictdt<-predict(dtmodel,test.cv,type='class')
t<-table(predictions=predictdt,actual=test.cv$Cluster)
outs[i]<-1-sum(diag(t))/sum(t)
pbar$step
}
outs
acc<-(1-outs)*100
acc
#mse1
#mean(mse1)
#acc<-(1-mse1)*100
#t
#sum(diag(t))
#sum(t)
#sum(diag(t))/sum(t)#
library(MASS)
library(rpart)
set.seed(123)
k.data1 <- read.csv( "Workbook8.csv", header = TRUE )
head( k.data1 )
dataframe<-k.data1
dataframe$Group=NULL
#dataframe$Gender=NULL
#dataframe$x1=NULL
head(dataframe)
#dataframe<- Boston
str(dataframe)
hist(dataframe$Cluster)
dim(dataframe)
apply(dataframe,2,range)
maxvalue<-apply(dataframe,2,max)
maxvalue
minvalue<-apply(dataframe,2,min)
minvalue
dataframe<-as.data.frame(scale(dataframe,center=minvalue,scale=maxvalue-minvalue))
library(caTools)
ind<-sample.split(Y=dataframe$Cluster,SplitRatio = 0.8)
traindf<-dataframe[ind,]
testdf<-dataframe[!ind,]
dtmodel<-rpart(Cluster ~ . ,data=traindf,method='class')
printcp(dtmodel)
plotcp(dtmodel)
plot(dtmodel,uniform=TRUE)
text(dtmodel, use.n=TRUE, all=TRUE, cex=.8)
#post(dtmodel, file = "dt.ps")
#text(dtmodel)
summary(dtmodel)
predictdt<-predict(dtmodel,testdf,type='class')
t<-table(predictions=predictdt,actual=testdf$Cluster)
t
sum(diag(t))
sum(t)
sum(diag(t))/sum(t)
df1 <- read.csv( "new_data.csv", header = TRUE )
predictdt2<-predict(dtmodel,df1[435,],type='class')
predictdt2
shiny::runApp()
k.data <- read.csv( ("Workbook8.csv"), header = TRUE )
head( k.data )
dataframe<-k.data[1:434,]
dataframe$Group=NULL
str(dataframe)
hist(dataframe$Cluster)
dim(dataframe)
apply(dataframe,2,range)
maxvalue<-apply(dataframe,2,max)
maxvalue
minvalue<-apply(dataframe,2,min)
minvalue
dataframe<-as.data.frame(scale(dataframe,center=minvalue,scale=maxvalue-minvalue))
library(caret)
set.seed(3033)
intrain <- createDataPartition(y = dataframe$Cluster, p= 0.8, list = FALSE)
training <- dataframe[intrain,]
testing <- dataframe[-intrain,]
training[["Cluster"]] = factor(training[["Cluster"]])
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
View(i1)
set.seed(3233)
svm_Linear <- train(Cluster ~., data = training, method = "svmLinear",
trControl=trctrl,
preProcess = c("center", "scale"),
tuneLength = 10)
plot(svm_Linear)
test_pred <- predict(svm_Linear, newdata = testing,method="class")
k.data <- read.csv( ("Workbook8.csv"), header = TRUE )
head( k.data )
dataframe<-k.data[1:434,]
dataframe$Group=NULL
str(dataframe)
hist(dataframe$Cluster)
dim(dataframe)
apply(dataframe,2,range)
maxvalue<-apply(dataframe,2,max)
maxvalue
minvalue<-apply(dataframe,2,min)
minvalue
dataframe<-as.data.frame(scale(dataframe,center=minvalue,scale=maxvalue-minvalue))
library(caret)
set.seed(3033)
intrain <- createDataPartition(y = dataframe$Cluster, p= 0.8, list = FALSE)
training <- dataframe[intrain,]
testing <- dataframe[-intrain,]
training[["Cluster"]] = factor(training[["Cluster"]])
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
set.seed(3233)
svm_Linear <- train(Cluster ~., data = training, method = "svmLinear",
trControl=trctrl,
preProcess = c("center", "scale"),
tuneLength = 10)
svm_Linear
test_pred <- predict(svm_Linear, newdata = testing,method="class")
shiny::runApp()
runApp()
k.data <- read.csv( ("Workbook8.csv"), header = TRUE )
head( k.data )
dataframe<-k.data[1:434,]
dataframe$Group=NULL
str(dataframe)
hist(dataframe$Cluster)
dim(dataframe)
apply(dataframe,2,range)
maxvalue<-apply(dataframe,2,max)
maxvalue
minvalue<-apply(dataframe,2,min)
minvalue
dataframe<-as.data.frame(scale(dataframe,center=minvalue,scale=maxvalue-minvalue))
library(caret)
set.seed(3033)
intrain <- createDataPartition(y = dataframe$Cluster, p= 0.8, list = FALSE)
training <- dataframe[intrain,]
testing <- dataframe[-intrain,]
training[["Cluster"]] = factor(training[["Cluster"]])
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
set.seed(3233)
svm_Linear <- train(Cluster ~., data = training, method = "svmLinear",
trControl=trctrl,
preProcess = c("center", "scale"),
tuneLength = 10)
svm_Linear
svm_Linear2 <-train(Cluster ~., data = training, method = "svmLinear",
trControl=trctrl,
preProcess = c("center", "scale"),
tuneGrid = expand.grid(C = seq(0, 2, length = 20)))
svm_Linear2
test_pred <- predict(svm_Linear, newdata = testing,method="class")
tail( test_pred,1)
k.data <- read.csv( ("Workbook8.csv"), header = TRUE )
head( k.data )
dataframe<-k.data[1:434,]
dataframe$Group=NULL
str(dataframe)
hist(dataframe$Cluster)
dim(dataframe)
apply(dataframe,2,range)
maxvalue<-apply(dataframe,2,max)
maxvalue
minvalue<-apply(dataframe,2,min)
minvalue
dataframe<-as.data.frame(scale(dataframe,center=minvalue,scale=maxvalue-minvalue))
library(caret)
set.seed(3033)
intrain <- createDataPartition(y = dataframe$Cluster, p= 0.8, list = FALSE)
training <- dataframe[intrain,]
testing <- dataframe[-intrain,]
training[["Cluster"]] = factor(training[["Cluster"]])
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
set.seed(3233)
svm_Linear <- train(Cluster ~., data = training, method = "svmLinear",
trControl=trctrl,
preProcess = c("center", "scale"),
tuneLength = 10)
svm_Linear
svm_Linear2 <-train(Cluster ~., data = training, method = "svmLinear",
trControl=trctrl,
preProcess = c("center", "scale"),
tuneGrid = expand.grid(C = seq(0, 2, length = 20)))
svm_Linear2
plot(svm_Linear2)
test_pred <- predict(svm_Linear, newdata = testing,method="class")
shiny::runApp()
